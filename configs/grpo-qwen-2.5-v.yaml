# Model arguments
model_name_or_path: Qwen/Qwen2.5-VL-3B-Instruct
model_revision: main
torch_dtype: bfloat16
attn_implementation: flash_attention_2
bf16: true
tf32: true

# Data arguments
json_data_path: "./textvqa_cot_train_1_bbox_0.json"

# Training arguments
output_dir: ./checkpoints/qwen2_5-3b-grpo-updated
per_device_train_batch_size: 1
gradient_accumulation_steps: 2
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
learning_rate: 1.0e-6
lr_scheduler_type: linear
warmup_ratio: 0.0
beta: 0.04
max_prompt_length: 1280
max_completion_length: 256
num_generations: 8
use_vllm: false

max_pixels: 12845056  # Maximum number of pixels for image processing
min_pixels: 3136   # Minimum number of pixels for image processing

logging_strategy: steps
logging_steps: 1
save_strategy: steps
save_steps: 1000
seed: 42

push_to_hub: false
